{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Convolution layer\n",
        "\n",
        "Conv1d\n"
      ],
      "metadata": {
        "id": "p6b0-yIyGKM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "m = torch.nn.Conv1d(16, 33, 3, stride=2)\n",
        "input = torch.randn(20, 16, 50)\n",
        "output = m(input)\n",
        "\n",
        "print (input)\n",
        "print (output)"
      ],
      "metadata": {
        "id": "4wTQ7TGxGoXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Layer\n",
        "\n",
        "Linear"
      ],
      "metadata": {
        "id": "PszlwfGVNnTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin = torch.nn.Linear(3, 2)\n",
        "x = torch.rand(1, 3)\n",
        "print('Input:')\n",
        "print(x)\n",
        "\n",
        "print('\\n\\nWeight and Bias parameters:')\n",
        "for param in lin.parameters():\n",
        "    print(param)\n",
        "\n",
        "y = lin(x)\n",
        "print('\\n\\nOutput:')\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "FkiRU2h9Nt6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling Layer\n",
        "\n",
        "MaxPool2d"
      ],
      "metadata": {
        "id": "TC1dA_MNODqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 16, 3)\n",
        "print(my_tensor)\n",
        "\n",
        "maxpool_layer = torch.nn.MaxPool2d(3)\n",
        "print(maxpool_layer(my_tensor))\n",
        "\n",
        "#NOTE: Min Pool\n",
        "#print(-maxpool_layer(-my_tensor))\n"
      ],
      "metadata": {
        "id": "vr20IIdEOMPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AvgPool1d"
      ],
      "metadata": {
        "id": "IjD3xAgC9uWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pool with window of size=3, stride=1\n",
        "m = torch.nn.AvgPool1d(3, stride=1)\n",
        "output = m(torch.tensor([[[1., 2, 3, 4, 5, 6, 7]]]))\n",
        "\n",
        "print (output)"
      ],
      "metadata": {
        "id": "Bqhf51Ec-PAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization Layer\n",
        "\n",
        "BatchNorm1d"
      ],
      "metadata": {
        "id": "EEAs4wx6OjrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.randn(2, 3)\n",
        "print(my_tensor)\n",
        "\n",
        "print(my_tensor.mean())\n",
        "\n",
        "norm_layer = torch.nn.BatchNorm1d(3)\n",
        "normed_tensor = norm_layer(my_tensor)\n",
        "print(normed_tensor)\n",
        "\n",
        "print(normed_tensor.mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "xy8yceddOok1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GroupNorm"
      ],
      "metadata": {
        "id": "PzVDhoA48IhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(20, 6, 10, 10)\n",
        "# Separate 6 channels into 3 groups\n",
        "m = torch.nn.GroupNorm(3, 6)\n",
        "# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
        "m = torch.nn.GroupNorm(6, 6)\n",
        "# Put all 6 channels into a single group (equivalent with LayerNorm)\n",
        "m = torch.nn.GroupNorm(1, 6)\n",
        "# Activating the module\n",
        "output = m(input)\n",
        "\n",
        "print (input)\n",
        "print (output)"
      ],
      "metadata": {
        "id": "aFJty8zT8NA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LayerNorm"
      ],
      "metadata": {
        "id": "4L3_h7ZR8xa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP Example\n",
        "batch, sentence_length, embedding_dim = 20, 5, 10\n",
        "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
        "layer_norm = torch.nn.LayerNorm(embedding_dim)\n",
        "# Activate module\n",
        "layer_norm(embedding)\n",
        "\n",
        "# Image Example\n",
        "N, C, H, W = 20, 5, 10, 10\n",
        "input = torch.randn(N, C, H, W)\n",
        "# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
        "# as shown in the image below\n",
        "layer_norm = torch.nn.LayerNorm([C, H, W])\n",
        "output = layer_norm(input)\n",
        "\n",
        "print (input)\n",
        "print (output)\n"
      ],
      "metadata": {
        "id": "0rr7wNlP80WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout Layer\n",
        "\n",
        "Dropout"
      ],
      "metadata": {
        "id": "Oto6FeO7OyD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4)\n",
        "\n",
        "dropout = torch.nn.Dropout(p=0.5)\n",
        "print(dropout(my_tensor))\n"
      ],
      "metadata": {
        "id": "POCBV94LO1KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlphaDropout\n",
        "\n",
        "maintains self-normalizing"
      ],
      "metadata": {
        "id": "d8uYQ8G0405p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.nn.AlphaDropout(p=0.5)\n",
        "input = torch.randn(10, 8)\n",
        "output = m(input)\n",
        "\n",
        "print (input)\n",
        "print (output)"
      ],
      "metadata": {
        "id": "QVkBYnNW486w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-linear Activations\n",
        "\n",
        "LeakyReLU\n",
        "\n",
        "LeakyReLU(x)=max(0,x)+negative_slopeâˆ—min(0,x)"
      ],
      "metadata": {
        "id": "ORnoHrNTN6GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.nn.LeakyReLU(0.1)\n",
        "input = torch.randn(2)\n",
        "print (input)\n",
        "output = m(input)\n",
        "\n",
        "print (output)"
      ],
      "metadata": {
        "id": "Jl2-E5IFOGK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding Layer\n",
        "\n",
        "ReflectionPad1d"
      ],
      "metadata": {
        "id": "4ZJKI9dqPOmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.nn.ReflectionPad1d(2)\n",
        "input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)\n",
        "print (input)\n",
        "\n",
        "m(input)\n",
        "\n",
        "m = torch.nn.ReflectionPad1d((3, 1))\n",
        "print (m(input))\n"
      ],
      "metadata": {
        "id": "mA0XbvEQPkiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-linear Activations\n",
        "\n",
        "Softmax"
      ],
      "metadata": {
        "id": "CX9TLqp5Qkbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.nn.Softmax(dim=1)\n",
        "input = torch.randn(2, 3)\n",
        "print (input)\n",
        "output = m(input)\n",
        "\n",
        "print (output)"
      ],
      "metadata": {
        "id": "qWLyqTc2QtXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization Layer\n",
        "\n",
        "BatchNorm1d"
      ],
      "metadata": {
        "id": "PVuspxaiRfCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With Learnable Parameters\n",
        "m = torch.nn.BatchNorm1d(100)\n",
        "\n",
        "# Without Learnable Parameters\n",
        "# m = torch.nn.BatchNorm1d(100, affine=False)\n",
        "\n",
        "input = torch.randn(20, 100)\n",
        "output = m(input)\n",
        "\n",
        "print (input)\n",
        "print (output)"
      ],
      "metadata": {
        "id": "tJMdGAuKRnfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent Layer\n",
        "\n",
        "RNN"
      ],
      "metadata": {
        "id": "ujD4n0KcSaUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = torch.nn.RNN(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)\n",
        "\n",
        "print (input)\n",
        "print (output)"
      ],
      "metadata": {
        "id": "mFXZy6QtSqQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Layer\n",
        "\n",
        "TransformerEncoderLayer"
      ],
      "metadata": {
        "id": "T2gHECQNTJ6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = torch.nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = encoder_layer(src)\n",
        "\n",
        "# Alternatively, when batch_first is True:\n",
        "encoder_layer = torch.nn.TransformerEncoderLayer(d_model=512, nhead=8, batch_first=True)\n",
        "src = torch.rand(32, 10, 512)\n",
        "out = encoder_layer(src)\n",
        "\n",
        "print (src)\n",
        "print (out)"
      ],
      "metadata": {
        "id": "eKQvPXaLTSkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparse Layer\n",
        "\n",
        "Embedding"
      ],
      "metadata": {
        "id": "XgsNHKyjUith"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# an Embedding module containing 10 tensors of size 3\n",
        "embedding = torch.nn.Embedding(10, 3)\n",
        "# a batch of 2 samples of 4 indices each\n",
        "input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
        "embedding(input)\n",
        "\n",
        "# example with padding_idx\n",
        "embedding = torch.nn.Embedding(10, 3, padding_idx=0)\n",
        "input = torch.LongTensor([[0, 2, 0, 5]])\n",
        "embedding(input)\n",
        "\n",
        "# example of changing `pad` vector\n",
        "padding_idx = 0\n",
        "embedding = torch.nn.Embedding(3, 3, padding_idx=padding_idx)\n",
        "embedding.weight\n",
        "\n",
        "with torch.no_grad():\n",
        "  embedding.weight[padding_idx] = torch.ones(3)\n",
        "embedding.weight\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ql13jDUvUofv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distance Function\n",
        "\n",
        "PairwiseDistance"
      ],
      "metadata": {
        "id": "meDX9vTPV-mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdist = torch.nn.PairwiseDistance(p=2)\n",
        "input1 = torch.randn(100, 128)\n",
        "input2 = torch.randn(100, 128)\n",
        "output = pdist(input1, input2)\n",
        "\n",
        "print (input1)\n",
        "print (input2)\n",
        "print (output)\n"
      ],
      "metadata": {
        "id": "04QO6zxhWHqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function\n",
        "\n",
        "CrossEntropyLoss"
      ],
      "metadata": {
        "id": "QZWi6BMSWdhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of target with class indices\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "\n",
        "print (input)\n",
        "print (output)\n",
        "\n",
        "# Example of target with class probabilities\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5).softmax(dim=1)\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "\n",
        "print (input)\n",
        "print (output)"
      ],
      "metadata": {
        "id": "N4hHx6xXWmp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vision Layer\n",
        "\n",
        "PixelShuffle"
      ],
      "metadata": {
        "id": "zMAtcxtbXEsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_shuffle = torch.nn.PixelShuffle(3)\n",
        "input = torch.randn(1, 9, 4, 4)\n",
        "print (input.size())\n",
        "output = pixel_shuffle(input)\n",
        "print(output.size())\n"
      ],
      "metadata": {
        "id": "zla_ggH6XPxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle Layer\n",
        "\n",
        "ChannelShuffle"
      ],
      "metadata": {
        "id": "bzLxE0clXw07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channel_shuffle = torch.nn.ChannelShuffle(2)\n",
        "input = torch.randn(1, 4, 2, 2)\n",
        "print(input)\n",
        "\n",
        "output = channel_shuffle(input)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "klWMuALcX46M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataParallel Layer\n",
        "\n",
        "DataParallel"
      ],
      "metadata": {
        "id": "1lG4DOkiYL7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])\n",
        "output = net(input_var)  # input_var can be on any device, including CPU\n",
        "\n"
      ],
      "metadata": {
        "id": "8h2B6nqCYS-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilities\n",
        "\n",
        "spectral_norm"
      ],
      "metadata": {
        "id": "J8eidPeOYj4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.nn.utils.spectral_norm(torch.nn.Linear(20, 40))\n",
        "\n",
        "m.weight_u.size()\n"
      ],
      "metadata": {
        "id": "alSInpGmZPkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten"
      ],
      "metadata": {
        "id": "-T3UTmq52B6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(32, 1, 5, 5)\n",
        "print (input.size())\n",
        "\n",
        "# With default parameters\n",
        "m = torch.nn.Flatten()\n",
        "output = m(input)\n",
        "output.size()\n",
        "\n",
        "# With non-default parameters\n",
        "m = torch.nn.Flatten(0, 2)\n",
        "output = m(input)\n",
        "\n",
        "print (output.size())\n"
      ],
      "metadata": {
        "id": "DotuB1z52GDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_dLYVRma3fG_"
      }
    }
  ]
}